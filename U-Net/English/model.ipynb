{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net\n",
    "\n",
    "<img src=\"images/unet.png\" width=\"30%\" height=\"10%\">\n",
    "\n",
    "\n",
    "This notebook is a PyTorch implementation of the U-Net model for image segmentation. The model is based on the paper [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597) by Olaf Ronneberger, Philipp Fischer, and Thomas Brox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1. Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import CenterCrop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implementing the blocks of the U-Net model\n",
    "\n",
    "<img src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\" width=\"70%\" height=\"70%\">\n",
    "\n",
    "As it is clear from the above, in the model some of the steps are repeated. For example, down sampling and up sampling processes are repeated each 4 times. This is why we are going to split models into two parts: **Down Sampling Block** and **Up Sampling Block**. Then we will combine them to create the U-Net model. \n",
    "\n",
    "##### &nbsp; **2.1** Down Sampling Block (Encoder)\n",
    "##### &nbsp; **2.2** Up Sampling Block (Decoder)\n",
    "##### &nbsp; **2.3** U-Net Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Down Sampling Block\n",
    "\n",
    "![Down Sampling Block](images/down_sampling_block.png)\n",
    "\n",
    "This block contains two convolutional layers with a kernel size of 3x3 and a max pooling layer with a kernel size of 2x2 and a stride of 2x2. After each convolutional layer Batch Normalization and ReLU is applied to the output. The max pooling layer is used to reduce the spatial dimensions of the input by a factor of 2. The number of filters in the convolutional layers is doubled after each down sampling block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSamplingBlock(nn.Module):\n",
    "    def __init__(self, in_filter_num, out_filter_num=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if out_filter_num is None:\n",
    "            out_filter_num = in_filter_num*2\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_features=out_filter_num)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(num_features=out_filter_num)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_filter_num, out_channels=out_filter_num, kernel_size=(3,3))\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_filter_num, out_channels=out_filter_num, kernel_size=(3,3))\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : (batch_size, in_filter_num, dim, dim)\n",
    "        x = self.relu(self.conv1(x)) # x : (batch_size, out_filter_num, dim-2, dim-2)\n",
    "        x = self.batch_norm1(x) # x : (batch_size, out_filter_num, dim-2, dim-2)\n",
    "        x = self.relu(self.conv2(x)) # x : (batch_size, out_filter_num, dim-4, dim-4)\n",
    "        x = self.batch_norm2(x) # x : (batch_size, out_filter_num, dim-4, dim-4)\n",
    "        out = self.max_pool(x) # x : (batch_size, out_filter_num, (dim-4)/2 , (dim-4)/2 )\n",
    "        return out, x        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Up Sampling Block\n",
    "\n",
    "![Up Sampling Block](images/up_sampling_block.png)\n",
    "\n",
    "This block contains one Up convolutional layer and two Convolutional layers. The Up convolutional layer is used to upsample the input. The two Convolutional layers are used to reduce the number of channels. The Up convolutional layer is followed by a concatenation layer which concatenates the output of the Up convolutional layer with the output of the corresponding Down convolutional layer. The concatenation layer is followed by two Convolutional layers. The output of the second Convolutional layer is the output of the Up Sampling Block. Each Convolutional layer is followed by a Batch Normalization layer and a ReLU activation layer as well as the Down Sample Block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSamplingBlock(nn.Module):\n",
    "    def __init__(self, in_filter_num, out_filter_num=None):\n",
    "        super().__init__()\n",
    "\n",
    "        if out_filter_num is None:\n",
    "            out_filter_num = in_filter_num//2\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_features=out_filter_num)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(num_features=out_filter_num)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.up_conv = nn.ConvTranspose2d(in_channels=in_filter_num,out_channels=out_filter_num, kernel_size=(2,2), stride=2)\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_filter_num,out_channels=out_filter_num, kernel_size=(3,3))\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_filter_num,out_channels=out_filter_num, kernel_size=(3,3)) \n",
    "\n",
    "    def forward(self, x, enc_out):\n",
    "\n",
    "        x = self.up_conv(x)\n",
    "        \n",
    "        x_size = tuple(x.shape[-2:])\n",
    "        crop = CenterCrop(size=x_size)\n",
    "        cropped_enc = crop(enc_out)\n",
    "        concatenated_input = torch.cat((cropped_enc,x),dim=1)\n",
    "    \n",
    "        x = self.relu(self.conv1(concatenated_input))\n",
    "        x = self.batch_norm1(x)        \n",
    "        x = self.relu(self.conv2(x))\n",
    "        out = self.batch_norm2(x)\n",
    "        return out\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. U-Net\n",
    "\n",
    "<img src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\" centered width=\"60%\" height=\"60%\">\n",
    "\n",
    "In this last block we are going to finish the U-Net model. Firstly we are going to define 4 Down Sampling Blocks and 4 Up Sampling Blocks. Between them there should be one last double convolutional layers. Then lastly we are going to define the final block which is going to be a convolutional layer with 1x1 kernel size. This layer is going to be used to get the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channel_num, out_channel_num, filter_num=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.downsample_1 = DownSamplingBlock(in_filter_num=in_channel_num, out_filter_num=filter_num) # in_filter_num= 3, out_filter_num= 64\n",
    "        self.downsample_2 = DownSamplingBlock(in_filter_num=filter_num) # in_filter_num= 64, out_filter_num= 128\n",
    "        self.downsample_3 = DownSamplingBlock(in_filter_num=filter_num*2) # in_filter_num= 128, out_filter_num= 256\n",
    "        self.downsample_4 = DownSamplingBlock(in_filter_num=filter_num*4) # in_filter_num= 256, out_filter_num= 512\n",
    "\n",
    "        self.bottom_conv1 = nn.Conv2d(in_channels=filter_num*8, out_channels= filter_num*16, kernel_size=(3,3)) # in_filter_num= 512, out_filter_num= 1024\n",
    "        self.bottom_conv2 = nn.Conv2d(in_channels=filter_num*16, out_channels= filter_num*16, kernel_size=(3,3)) # in_filter_num= 1024, out_filter_num= 1024\n",
    "\n",
    "        self.upsample_1  = UpSamplingBlock(in_filter_num=filter_num*16) # in_filter_num= 1024, out_filter_num= 512\n",
    "        self.upsample_2  = UpSamplingBlock(in_filter_num=filter_num*8) # in_filter_num= 512, out_filter_num= 256\n",
    "        self.upsample_3  = UpSamplingBlock(in_filter_num=filter_num*4) # in_filter_num= 256, out_filter_num= 128\n",
    "        self.upsample_4  = UpSamplingBlock(in_filter_num=filter_num*2) # in_filter_num= 128, out_filter_num= 64\n",
    "\n",
    "        self.top_conv = nn.Conv2d(in_channels=filter_num, out_channels=out_channel_num, kernel_size=(1,1))\n",
    "\n",
    "        # In total 23 conv layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : (batch_size, 1, 572, 572)\n",
    "        x, enc_out1 = self.downsample_1(x) # x : (batch_size, 64 , 284, 284), enc_out1: (batch_size, 64 , 568, 568)\n",
    "        x, enc_out2 = self.downsample_2(x) # x : (batch_size, 128, 140, 140), enc_out2: (batch_size, 128, 280, 280)\n",
    "        x, enc_out3 = self.downsample_3(x) # x : (batch_size, 256, 68 , 68 ), enc_out3: (batch_size, 256, 136, 136)\n",
    "        x, enc_out4 = self.downsample_4(x) # x : (batch_size, 512, 32 , 32 ), enc_out4: (batch_size, 512, 64 , 64 )\n",
    "\n",
    "        x = self.relu(self.bottom_conv1(x)) # x : (batch_size, 1024 , 30, 30)\n",
    "        x = self.relu(self.bottom_conv2(x)) # x : (batch_size, 1024 , 28, 28)\n",
    "\n",
    "        x = self.upsample_1(x, enc_out4) # x : (batch_size, 512 , 52, 52)\n",
    "        x = self.upsample_2(x, enc_out3) # x : (batch_size, 256 , 100, 100)\n",
    "        x = self.upsample_3(x, enc_out2) # x : (batch_size, 128 , 196, 196)\n",
    "        x = self.upsample_4(x, enc_out1) # x : (batch_size, 64 , 388, 388)\n",
    "        out = self.top_conv(x) # out : (batch_size, 2 , 388, 388)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End\n",
    "### If you have any questions, please contact me.\n",
    "Mail: i_konak@hotmail.com\n",
    "<br>\n",
    "Linkedin: https://www.linkedin.com/in/ismail-konak/\n",
    "<br>\n",
    "GitHub: https://github.com/IsmailKonak"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
