{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Transformer Model\n",
    "\n",
    "![Transformer Model](transformer1.png)\n",
    "\n",
    "Bu Notebookta sizlere bir Transformer modeli kodlayacağım. Transformer mimarisi, Ashish Vaswani ve diğerleri tarafından yazılan [Attention is all you need](https://arxiv.org/abs/1706.03762) makalesine dayanmaktadır. Model, [PyTorch](https://pytorch.org/) kullanılarak implement edilmiştir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 1. Kütüphaneleri İçe Aktarma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "# Eğer GPU kullanılabiliyorsa (Gerçi bu modelde GPU kullanmak bir seçenekten ziyade ne yazık ki bir zorunluluk :D)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2. Hiperparametreleri Tanımlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model= 256 # Embed size olarak da bilinir: token embedding vektörünün boyutu\n",
    "nhead = 4 # Multi Head Attention katmanındaki head sayısı\n",
    "num_encoder_layers = 1 # Encoderdaki EncoderStack sayısı\n",
    "num_decoder_layers = 1 # Decoderdaki DecoderStack sayısı\n",
    "forward_expansion= 4 # Transformer Encoder/Decoder içindeki ileri beslemeli ağdaki nöronların artış oranı\n",
    "learning_rate = 3e-4 # Adam optimizer'ının learning rate değeri\n",
    "block_size = 128 # Girdi dizisinin (maksimum) uzunluğu\n",
    "vocab_size = 30000 # Kelime haznesinin boyutu (vocab_size) (Tokenizer tarafından bilinen token sayısı)\n",
    "dropout = 0.25 # Dropout katmanlarının atma oranı\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3. Transformer Bloklarını Oluşturma\n",
    "\n",
    " #### 3.1. Positional Encoding\n",
    "\n",
    " Bu bölümde Positional Encoding (pozisyonel kodlama), makalede açıklandığı gibi kullanacağız.\n",
    "\n",
    " Bunun için aşağıdaki formülü kullanacağız:\n",
    "\n",
    "\n",
    " $$PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})$$\n",
    " $$PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_sequence_length):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self):\n",
    "        position = torch.arange(self.max_sequence_length, device=device, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.d_model, 2, device=device, dtype=torch.float32) * (-math.log(10000.0) / self.d_model))\n",
    "        pe = torch.zeros(self.max_sequence_length, self.d_model, device=device, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 3.2. Embedding Bloğu\n",
    "\n",
    " Bu bölümde Embedding bloğunu oluşturacağız. Bu blok, girdi verilerini bir vektör temsiline dönüştürmek için kullanılacak.\n",
    "\n",
    " Bu blok temel olarak 2 bölümden oluşuyor:\n",
    " 1. Token Embedding\n",
    " 2. Positional Encoding\n",
    "\n",
    " Positional Encoding bloğunu yukarıda ayrı bir sınıf olarak tanımladık.\n",
    "\n",
    " Bu nedenle şimdi \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, d_model, vocab_size, block_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, block_size)\n",
    "    def forward(self, x):\n",
    "        out = self.token_embedding(x) + self.positional_encoding()\n",
    "        return  out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 3.3. Multi Head Attention\n",
    "\n",
    " Bu bölümde Multi Head Attention katmanını uygulayacağız. Çoklu kafa dikkat katmanı, $h$ adet dikkat başlığına sahiptir. Her dikkat başlığının ayrı bir sorgu, anahtar ve değer matrisi vardır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # d_model'in num_heads'e bölünebilir olup olmadığını kontrol ediyoruz\n",
    "        assert d_model % num_heads == 0, \"d_model num_heads'e bölünebilmelidir\"\n",
    "        \n",
    "        # Her başlığa d_model'in num_heads'e bölünmüş boyutunu atamak için d_model'i num_heads'e bölüyoruz. Bu hem d_k hem de d_v için geçerlidir\n",
    "        self.d_qkv = d_model // num_heads\n",
    "\n",
    "        # Sorguları, anahtarları ve değerleri projekte etmek için nn.Linear kullanıyoruz. Aynı lineer projeksiyonu tüm başlıklar için kullanıyoruz.\n",
    "        # Bunun nedeni, sorguları, anahtarları ve değerleri projekte etmek için ayrı ayrı matrisler kullanmak yerine tek bir matris çarpımı kullanmamıza olanak tanımasıdır.\n",
    "        # Bu, her biri için ayrı matrisler kullanmaktan daha verimlidir.\n",
    "        self.W_keys = nn.Linear(d_model, d_model)\n",
    "        self.W_queries = nn.Linear(d_model, d_model)\n",
    "        self.W_values = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # Çıktıyı projekte etmek için tek bir lineer projeksiyon kullanıyoruz\n",
    "        self.linear_proj = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout) \n",
    "\n",
    "    def forward(self, key_src, query_src, value_src, mask=None):\n",
    "        \n",
    "        # Girdi yığınının şeklini alıyoruz\n",
    "        B,T,C = key_src.shape # (batch_size, seq_len, d_model)\n",
    "\n",
    "\n",
    "        # Sorguları, anahtarları ve değerleri ilgili ağırlık matrislerini kullanarak projekte ediyoruz\n",
    "        keys = self.W_keys(key_src) # (batch_size, seq_len, d_model)\n",
    "        queries = self.W_queries(query_src) # (batch_size, seq_len, d_model)\n",
    "        values = self.W_values(value_src) # (batch_size, seq_len, d_model)\n",
    "        \n",
    "\n",
    "        # Sorguları, anahtarları ve değerleri çoklu başlıklara bölmek için yeniden şekillendiriyoruz\n",
    "        \n",
    "        keys = keys.view(B,T,self.num_heads,self.d_qkv) # (batch_size, seq_len, num_heads, d_qkv)\n",
    "        queries = queries.view(B,T,self.num_heads,self.d_qkv) # (batch_size, seq_len, num_heads, d_qkv)\n",
    "        values = values.view(B,T,self.num_heads,self.d_qkv) # (batch_size, seq_len, num_heads, d_qkv)\n",
    "\n",
    "\n",
    "        # Sorguları, anahtarları ve değerleri tensörün şeklini (batch_size, num_heads, seq_len, d_qkv) yapacak şekilde yer değiştiriyoruz\n",
    "\n",
    "        keys = keys.transpose(1,2) # (batch_size, num_heads, seq_len, d_qkv)\n",
    "        queries = queries.transpose(1,2) # (batch_size, num_heads, seq_len, d_qkv)\n",
    "        values = values.transpose(1,2) # (batch_size, num_heads, seq_len, d_qkv)\n",
    "\n",
    "        # Dikkat puanlarını hesaplıyoruz.\n",
    "        atn_scr = queries @ keys.transpose(-2,-1) # (batch_size, num_heads, seq_len, seq_len)\n",
    "        # Dikkat puanlarını ölçeklendiriyoruz ve maskeyi uyguluyoruz (varsa)\n",
    "        scaled_atn_scr = atn_scr / self.d_qkv**-0.5\n",
    "        if mask is not None:\n",
    "            scaled_atn_scr = scaled_atn_scr.masked_fill(mask==0,float('-inf'))\n",
    "        \n",
    "        # Dikkat ağırlıklarını hesaplamak için softmax aktivasyonunu uyguluyoruz\n",
    "        attention_weights = torch.softmax(scaled_atn_scr, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)  # Dropout uyguluyoruz\n",
    "        # Son olarak, dikkat ağırlıklarını değerlerle çarpıyoruz\n",
    "        out = attention_weights @ values\n",
    "        out = out.transpose(1, 2)\n",
    "        # Matrisi (batch_size, seq_len, d_model) şekline dönüştürmek için yeniden şekillendiriyoruz\n",
    "        out = out.reshape(B, T, C)\n",
    "        # Bir sonraki katmana beslemek için son bir lineer projeksiyon uyguluyoruz\n",
    "        out = self.linear_proj(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 3.4. İleri Beslemeli Sinir Ağı\n",
    "\n",
    " Bu bölümde makalede olduğu gibi FFN'yi uygulayacağız. Bu, ağın içinde 2 lineer katman ve bu katmanlar arasında ReLU aktivasyon fonksiyonunun olduğu anlamına gelir. Ağın giriş ve çıkış boyutu aynı kalır, ancak içeride boyutu bir katsayı ile çarpmak üzere artırırız, bu katsayıya \"Forward Expansion\" denir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNet(nn.Module):\n",
    "    def __init__(self, d_model, forward_expansion, dropout=0.1):  \n",
    "        super(FeedForwardNet, self).__init__()\n",
    "        # İlk lineer katmanın çıkış boyutu forward_expansion kez d_model (d_model*forward_expansion)\n",
    "        self.fc1 = nn.Linear(d_model, d_model * forward_expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        # İkinci lineer katmanın giriş boyutu d_model * forward_expansion ve çıkışı sadece d_model'dir \n",
    "        # İleri beslemeli ağa giren girdinin boyutunu aynı tutabilmek ve artıklı bağlantı kullanabilmek için\n",
    "        self.fc2 = nn.Linear(d_model * forward_expansion, d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)  \n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 3.5. Encoder Stack\n",
    "\n",
    " Bu bölümde Encoder Stack oluşturacağız. Encoder Stack 1 MHA ve 1 FFN bloğundan oluşur. Bu bloğun her alt birimini Layer Normalization ve Residual Connection takip eder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderStack(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, forward_expansion, dropout=0.1): \n",
    "        super().__init__()\n",
    "        self.MHA = MultiHeadAttention(d_model=d_model, num_heads=num_heads, dropout=dropout)\n",
    "        self.FFN = FeedForwardNet(d_model=d_model, forward_expansion=forward_expansion, dropout=dropout)\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)  # Dropout katmanı eklendi\n",
    "        self.dropout2 = nn.Dropout(dropout)  # Dropout katmanı eklendi\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.dropout1(self.MHA(x, x, x))  # Dropout uyguluyoruz + Residual connection\n",
    "        norm_out = self.layer_norm1(out) # Layer Normalization uyguluyoruz\n",
    "        out = norm_out + self.dropout2(self.FFN(norm_out))  # Dropout uyguluyoruz + Residual connection\n",
    "        norm_out = self.layer_norm2(out) # Layer Normalization uyguluyoruz\n",
    "        return norm_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 3.6. Encoder\n",
    "\n",
    " Bu bölümde Encoder bloğunu oluşturuyoruz. Encoder bloğu bir Embedding katmanı ve N adet Encoder Stack bloğundan (N = num_layers) oluşur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, block_size, d_model, num_heads, forward_expansion, num_layers):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        self.d_model = d_model\n",
    "        self.embeding_layer = EmbeddingLayer(d_model, vocab_size, block_size)\n",
    "        self.layers = nn.ModuleList([EncoderStack(d_model, num_heads, forward_expansion) for _ in range(num_layers)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embeding_layer(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 3.7. Decoder Stack\n",
    "\n",
    " Bu bölümde Decoder Stack bloğunu oluşturacağız. Decoder Stack bloğu, 2 MHA (birisi maskelemeli dikkat, diğeri çapraz dikkat için) ve 1 FFN bloğundan oluşur. Bu bloğun da her alt birimini Layer Normalization ve Residual Connection takip eder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderStack(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, forward_expansion, dropout=0.1):  \n",
    "        super(DecoderStack, self).__init__()\n",
    "        self.Masked_MHA = MultiHeadAttention(d_model=d_model, num_heads=num_heads, dropout=dropout)\n",
    "        self.Crossed_MHA = MultiHeadAttention(d_model=d_model, num_heads=num_heads, dropout=dropout)\n",
    "        self.FFN = FeedForwardNet(d_model=d_model, forward_expansion=forward_expansion, dropout=dropout)\n",
    "        self.LayerNorm1 = nn.LayerNorm(d_model)\n",
    "        self.LayerNorm2 = nn.LayerNorm(d_model)\n",
    "        self.LayerNorm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)  \n",
    "        self.dropout2 = nn.Dropout(dropout)  \n",
    "        self.dropout3 = nn.Dropout(dropout)  \n",
    "\n",
    "    def forward(self, x, encoder_out, trg_mask):\n",
    "        masked_att_out = self.dropout1(self.Masked_MHA(x, x, x, trg_mask)) \n",
    "        masked_att_out = self.LayerNorm1(masked_att_out + x)\n",
    "        crossed_att_out = self.dropout2(self.Crossed_MHA(encoder_out, masked_att_out, encoder_out)) \n",
    "        crossed_att_out = self.LayerNorm2(crossed_att_out + masked_att_out)\n",
    "        ffn_out = self.dropout3(self.FFN(crossed_att_out))  \n",
    "        ffn_out = self.LayerNorm3(ffn_out + crossed_att_out)\n",
    "        return ffn_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 3.8. Decoder\n",
    "\n",
    " Bu bölümde Decoder bloğunu oluşturuyoruz. Decoder bloğu bir Embedding katmanı ve N adet Decoder Stack bloğundan (N = num_layers) oluşur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,vocab_size, block_size, d_model, num_heads, forward_expansion, num_layers):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        self.d_model = d_model\n",
    "        self.embeding_layer = EmbeddingLayer(d_model, vocab_size, block_size)\n",
    "        self.layers = nn.ModuleList([DecoderStack(d_model, num_heads, forward_expansion) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, encoder_output, trg_mask):\n",
    "        x = self.embeding_layer(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_output, trg_mask)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 3.9. Transformer\n",
    "\n",
    " Son olarak, Transformer modelini oluşturuyoruz. Transformer modeli, Encoder ve Decoder bloklarının birleşiminden oluşur. Encoder, Embedding katmanı ve N adet Encoder Stack katmanından oluşur. Decoder ise Embedding katmanını ve N adet Decoder Stack katmanından oluşur. En son da bu modelin ucuna çıktı boyutu Tokenizer'ın öğrendiği kelime sayısına eşit bir lineer katman koyarız. Bu son katman sayesinde Decoder'dan aldığımız çıktıyı tahmin yapabilmek için kullanılabilecek hale getirebilriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, block_size, d_model, nhead, num_encoder_layers, num_decoder_layers,\n",
    "                 forward_expansion, learning_rate, dropout=0.1): \n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(vocab_size, block_size, d_model, nhead, forward_expansion, num_encoder_layers)\n",
    "        self.decoder = Decoder(vocab_size, block_size, d_model, nhead, forward_expansion, num_decoder_layers)\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.linear = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src, trg, src_mask, trg_mask):\n",
    "        encoder_output = self.encoder(src)\n",
    "        decoder_output = self.decoder(trg, encoder_output, trg_mask)\n",
    "        output = self.linear(decoder_output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Son\n",
    "\n",
    "### Herhangi bir sorunuz olursa, bana aşağıdaki iletişim bilgilerimden kolayca ulaşabilirsiniz.\n",
    "\n",
    "Mail: i_konak@hotmail.com\n",
    "\n",
    "Linkedin: https://www.linkedin.com/in/ismail-konak/\n",
    "\n",
    "GitHub: https://github.com/IsmailKonak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
