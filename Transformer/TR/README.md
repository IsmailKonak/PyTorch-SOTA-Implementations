# Transformer Model Implementasyonu

PyTorch kullanarak Transformer modelini implement ettiğimiz repoya hoş geldiniz! Bu proje, doğal dil işleme alanında devrim yaratan Transformer mimarisinin kapsamlı, from scratch bir implementasyonunu sağlamayı amaçlamaktadır.

## İçindekiler

- **Giriş**
- **Proje Durumu**
- **Özellikler**
- **Başlarken**

## Giriş

Transformer modeli, "Attention Is All You Need" adlı makalede tanıtılan, sıralı diziler boyunca bağlamsal bilgiyi yakalamak için Self-Attention mekanizmasını kullanan çığır açan bir mimaridir. Bugün doğal dil işleme alanında kullanılan BERT, GPT ve daha fazlası gibi çeşitli en son teknoloji modellerin temel yapı taşını oluşturmuştur.

Bu repo, Transformer modelini adım adım PyTorch ile implement ederek altındaki mantığını çözmeyi amaçlar. Transformer'lara yeniyseniz veya ayrıntılara derinlemesine inmek istiyorsanız, burada değerli bilgiler ve eğitim içeriği bulacağınızı umuyorum.

## Proje Durumu

🎉 **Proje Tamamlandı**: Bu proje artık tamamlandı! Transformer mimarisini PyTorch kullanarak implement ettik.

Tamamlanan implementasyonu keşfetmekten ve Transformer modelinin ayrıntılarına dalmaktan çekinmeyin. Herhangi bir sorunuz veya öneriniz varsa lütfen bize ulaşınız.


## Özellikler

- Transformer mimarisinin temel bileşenlerinin ayrıntılı implementasyonu.
- Anlaşılmasına yardımcı olmak için eğitici kod yorum ve açıklamaları.
- Deneme ve öğrenme kolaylığı için PyTorch tabanlı uygulama.


## Başlarken

1. Bu repoyu klonlayın.
2. Devam eden implementasyonu anlamak için kodu bol bol kurcalayın.
3. Deney yapmak, değişiklik yapmak ve katkıda bulunmakta özgürsünüz.



