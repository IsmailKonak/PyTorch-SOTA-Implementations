{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "block_size = 128\n",
    "sample_num = 1000000 # 1M\n",
    "batch_size = 256\n",
    "max_vocab_size = 30000\n",
    "\n",
    "d_model = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "europarl_en = open('Data/europarl-v7.fr-en.en', encoding='utf-8').read().split('\\n')[:sample_num]\n",
    "europarl_fr = open('Data/europarl-v7.fr-en.fr', encoding='utf-8').read().split('\\n')[:sample_num]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_iterator = iter(europarl_en)\n",
    "fr_iterator = iter(europarl_fr)\n",
    "\n",
    "def get_or_build_tokenizer(path, iterator, lang, max_vocab_size):\n",
    "    tokenizer_path = Path(path+\"tokenizer_\"+lang+\".json\")\n",
    "    if not Path.exists(tokenizer_path):\n",
    "        tokenizer = Tokenizer(WordLevel(unk_token='[UNK]'))\n",
    "        tokenizer.pre_tokenizer = Whitespace()\n",
    "        trainer = WordLevelTrainer(special_tokens=[\"[UNK]\",\"[PAD]\",\"[BOS]\",\"[EOS]\"], min_frequency=2, vocab_size=max_vocab_size)\n",
    "        tokenizer.train_from_iterator(iterator, trainer=trainer)\n",
    "        tokenizer.save(str(tokenizer_path))\n",
    "    else:\n",
    "        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/ismailko/Documents/Projects/All Neural Networks Scratch/Transformer/\"\n",
    "tokenizer_en = get_or_build_tokenizer(path,en_iterator,\"english\", max_vocab_size=max_vocab_size)\n",
    "tokenizer_fr = get_or_build_tokenizer(path,fr_iterator,\"french\", max_vocab_size=max_vocab_size)\n",
    "\n",
    "class MachineTranslationDataset(Dataset):\n",
    "    def __init__(self,sentences_src,sentences_trg, tokenizer_src,tokenizer_trg, seq_len):\n",
    "        self.sentences_src = sentences_src\n",
    "        self.sentences_trg = sentences_trg\n",
    "        self.tokenizer_src = tokenizer_src\n",
    "        self.tokenizer_trg = tokenizer_trg\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        self.bos_token = torch.tensor([tokenizer_src.token_to_id(\"[BOS]\")], dtype=torch.int64)\n",
    "        self.eos_token = torch.tensor([tokenizer_src.token_to_id(\"[EOS]\")], dtype=torch.int64)\n",
    "        self.pad_token = torch.tensor([tokenizer_src.token_to_id(\"[PAD]\")], dtype=torch.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences_src)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        english_sentence = self.sentences_src[idx]\n",
    "        french_sentence = self.sentences_trg[idx]\n",
    "\n",
    "        english_sentence = torch.tensor(self.tokenizer_src.encode(english_sentence).ids, dtype=torch.int64)\n",
    "        french_sentence = torch.tensor(self.tokenizer_trg.encode(french_sentence).ids, dtype=torch.int64)\n",
    "        # add bos and eos tokens\n",
    "        english_sentence = torch.cat((self.bos_token, english_sentence, self.eos_token))\n",
    "        french_sentence = torch.cat((self.bos_token, french_sentence, self.eos_token))\n",
    "\n",
    "        # pad sentences to seq_len\n",
    "        english_sentence = torch.cat((english_sentence, self.pad_token.repeat(self.seq_len - english_sentence.shape[0])))\n",
    "        french_sentence = torch.cat((french_sentence, self.pad_token.repeat(self.seq_len - french_sentence.shape[0])))\n",
    "\n",
    "        return english_sentence, french_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MachineTranslationDataset(europarl_en, europarl_fr, tokenizer_en, tokenizer_fr, block_size)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_sequence_length):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self):\n",
    "        even_i = torch.arange(0, self.d_model, 2).float()\n",
    "        denominator = torch.pow(10000, even_i/self.d_model)\n",
    "        position = torch.arange(self.max_sequence_length).reshape(self.max_sequence_length, 1)\n",
    "        even_PE = torch.sin(position / denominator)\n",
    "        odd_PE = torch.cos(position / denominator)\n",
    "        stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
    "        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
    "        return PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, d_model, vocab_size, block_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, block_size)\n",
    "    def forward(self, x):\n",
    "        out = self.token_embedding(x) + self.positional_encoding()\n",
    "        return  out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 128, 512])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(data_loader))\n",
    "src = x[0]\n",
    "\n",
    "embed_layer = EmbeddingLayer(d_model,max_vocab_size, block_size)\n",
    "\n",
    "embed_layer(src).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_qkv = d_model // num_heads\n",
    "\n",
    "        self.W_keys = nn.Linear(d_model, d_model)\n",
    "        self.W_queries = nn.Linear(d_model, d_model)\n",
    "        self.W_values = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, key_src, query_src, value_src, mask=None):\n",
    "        \n",
    "        B,T,C = key_src.shape # (batch_size, seq_len, d_model)\n",
    "\n",
    "        keys = self.W_keys(key_src) # (batch_size, seq_len, d_model)\n",
    "        queries = self.W_queries(query_src) # (batch_size, seq_len, d_model)\n",
    "        values = self.W_values(value_src) # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        keys = keys.view(B,T,self.num_heads,self.d_qkv) # (batch_size, seq_len, num_heads, d_qkv)\n",
    "        queries = queries.view(B,T,self.num_heads,self.d_qkv) # (batch_size, seq_len, num_heads, d_qkv)\n",
    "        values = values.view(B,T,self.num_heads,self.d_qkv) # (batch_size, seq_len, num_heads, d_qkv)\n",
    "\n",
    "        atn_scr = queries @ keys.transpose(-2,-1) # (batch_size, seq_len, num_heads, num_heads)\n",
    "        scaled_atn_scr = atn_scr / self.d_qkv**0.5\n",
    "        if mask is not None:\n",
    "            scaled_atn_scr = scaled_atn_scr.masked_fill(mask==0,'-inf')\n",
    "\n",
    "        attention_weights = torch.softmax(scaled_atn_scr, dim=-1) # (batch_size, seq_len, num_heads, num_heads)\n",
    "        out = attention_weights @ values # (batch_size, seq_len, num_heads, d_qkv)\n",
    "        out = out.transpose(1,2) # (batch_size, num_heads, seq_len, d_qkv)\n",
    "        out = out.reshape(B,T,C) # (batch_size, seq_len, d_model)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNet(nn.Module):\n",
    "    def __init__(self, d_model, forward_expansion):\n",
    "        super(FeedForwardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_model * forward_expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(d_model*forward_expansion, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderStack(nn.Module):\n",
    "    def __init__(self,d_model, num_heads, forward_expansion):\n",
    "        super().__init__()\n",
    "        self.MHA = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
    "        self.FFN = FeedForwardNet(d_model=d_model, forward_expansion=forward_expansion)\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # X = [batch_size, seq_len, d_model]\n",
    "        out = x + self.MHA(x, x, x) # [batch_size, seq_len, d_model]\n",
    "        norm_out = self.layer_norm1(out)\n",
    "        out = norm_out + self.FFN(norm_out) # [batch_size, seq_len, d_model]\n",
    "        norm_out = self.layer_norm2(out)\n",
    "        return norm_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, block_size, d_model, num_heads, forward_expansion, num_layers):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        self.d_model = d_model\n",
    "        self.embeding_layer = EmbeddingLayer(d_model, vocab_size, block_size)\n",
    "        self.layers = nn.ModuleList([EncoderStack(d_model, num_heads, forward_expansion) for _ in range(num_layers)])\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        x = self.embeding_layer(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderStack(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, forward_expansion):\n",
    "        super(DecoderStack, self).__init__()\n",
    "        self.Masked_MHA = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
    "        self.Crossed_MHA = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
    "        self.FFN = FeedForwardNet(d_model=d_model, forward_expansion=forward_expansion)\n",
    "        self.LayerNorm1 = nn.LayerNorm(d_model)\n",
    "        self.LayerNorm2 = nn.LayerNorm(d_model)\n",
    "        self.LayerNorm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self,x,encoder_out,trg_mask):\n",
    "        masked_att_out = self.Masked_MHA(x,x,x,trg_mask)\n",
    "        masked_att_out = self.LayerNorm1(masked_att_out + x)\n",
    "        crossed_att_out = self.Crossed_MHA(encoder_out,masked_att_out,encoder_out)\n",
    "        crossed_att_out = self.LayerNorm2(crossed_att_out + masked_att_out)\n",
    "        ffn_out = self.FFN(crossed_att_out)\n",
    "        ffn_out = self.LayerNorm3(ffn_out + crossed_att_out)\n",
    "        return ffn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,vocab_size, block_size, d_model, num_heads, forward_expansion, num_layers):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        self.d_model = d_model\n",
    "        self.embeding_layer = EmbeddingLayer(d_model, vocab_size, block_size)\n",
    "        self.layers = nn.ModuleList([Decoder(d_model, num_heads, forward_expansion) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, encoder_output, trg_mask):\n",
    "        x = self.embeding_layer(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_output, trg_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, block_size, d_model, nhead, num_encoder_layers, num_decoder_layers,\n",
    "                  forward_expansion):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(vocab_size, block_size, d_model, nhead, forward_expansion, num_encoder_layers)\n",
    "        self.decoder = Decoder(vocab_size, block_size, d_model, nhead, forward_expansion, num_decoder_layers)\n",
    "        self.out = nn.Linear(d_model*block_size, vocab_size)\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.mask = torch.tril(torch.ones((block_size, block_size)))\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        B, T = trg.shape\n",
    "        enc_src = self.encoder(src, mask=None)\n",
    "        out = self.decoder(trg, enc_src, self.mask)\n",
    "        out = self.out(out)\n",
    "        out = out.reshape(B, self.vocab_size)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
